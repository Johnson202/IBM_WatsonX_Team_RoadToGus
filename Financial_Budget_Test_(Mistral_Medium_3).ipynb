{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sevI9wc7c2g5"
      },
      "source": [
        "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
        "# Prompt Notebook with Chat - Prompt Lab Notebook v1.1.0\n",
        "This notebook contains steps and code to demonstrate inferencing of prompts\n",
        "generated in Prompt Lab in watsonx.ai with a chat format. It introduces Python API commands\n",
        "for authentication using API key and prompt inferencing using WML API.\n",
        "\n",
        "**Note:** Notebook code generated using Prompt Lab will execute successfully.\n",
        "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
        "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Prompt Lab as a notebook.</a>\n",
        "\n",
        "Some familiarity with Python is helpful. This notebook uses Python 3.10.\n",
        "\n",
        "## Notebook goals\n",
        "The learning goals of this notebook are:\n",
        "\n",
        "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
        "* Defining parameters of the Model object\n",
        "* Using the Model object to generate response using the defined model id, parameters and the prompt input\n",
        "\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ts3yrcLoc2g-"
      },
      "source": [
        "## watsonx API connection\n",
        "This cell defines the credentials required to work with watsonx API for Foundation\n",
        "Model inferencing.\n",
        "\n",
        "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
        "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ibm_watsonx_ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXRYfPCpdPW0",
        "outputId": "21119341-eb60-4f6a-b204-6dcbd568c637"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ibm_watsonx_ai in /usr/local/lib/python3.12/dist-packages (1.4.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (2.32.4)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (0.28.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (2.5.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=0.24.2 in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (2.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (2025.10.5)\n",
            "Requirement already satisfied: lomond in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (0.3.3)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (0.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (25.0)\n",
            "Requirement already satisfied: ibm-cos-sdk<2.15.0,>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (2.14.3)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.12/dist-packages (from ibm_watsonx_ai) (5.5.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->ibm_watsonx_ai) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->ibm_watsonx_ai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.29,>=0.27->ibm_watsonx_ai) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ibm_watsonx_ai) (0.16.0)\n",
            "Requirement already satisfied: ibm-cos-sdk-core==2.14.3 in /usr/local/lib/python3.12/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai) (2.14.3)\n",
            "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.14.3 in /usr/local/lib/python3.12/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai) (2.14.3)\n",
            "Requirement already satisfied: jmespath<=1.0.1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai) (1.0.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from ibm-cos-sdk-core==2.14.3->ibm-cos-sdk<2.15.0,>=2.12.0->ibm_watsonx_ai) (2.9.0.post0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=0.24.2->ibm_watsonx_ai) (2.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=0.24.2->ibm_watsonx_ai) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<2.3.0,>=0.24.2->ibm_watsonx_ai) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->ibm_watsonx_ai) (3.4.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from lomond->ibm_watsonx_ai) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->ibm_watsonx_ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<0.29,>=0.27->ibm_watsonx_ai) (4.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/ibm-granite-community/utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8zmtVa-uKIU",
        "outputId": "a035b300-948a-44c5-f278-bada86348ad9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ibm-granite-community/utils\n",
            "  Cloning https://github.com/ibm-granite-community/utils to /tmp/pip-req-build-b_7574wn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils /tmp/pip-req-build-b_7574wn\n",
            "  Resolved https://github.com/ibm-granite-community/utils to commit 3c725e243561d17b575a0a5496bfa3d3f28f6481\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from ibm-granite-community-utils==0.1.dev112) (1.2.1)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.12/dist-packages (from ibm-granite-community-utils==0.1.dev112) (0.3.79)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from ibm-granite-community-utils==0.1.dev112) (4.15.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ibm-granite-community-utils==0.1.dev112) (0.4.41)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ibm-granite-community-utils==0.1.dev112) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ibm-granite-community-utils==0.1.dev112) (1.33)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ibm-granite-community-utils==0.1.dev112) (6.0.3)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ibm-granite-community-utils==0.1.dev112) (25.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain_core->ibm-granite-community-utils==0.1.dev112) (2.11.10)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain_core->ibm-granite-community-utils==0.1.dev112) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_core->ibm-granite-community-utils==0.1.dev112) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_core->ibm-granite-community-utils==0.1.dev112) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_core->ibm-granite-community-utils==0.1.dev112) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain_core->ibm-granite-community-utils==0.1.dev112) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfeacd0cc2g_",
        "outputId": "02ee9e58-afd5-426b-c7fc-47e7ae0da685"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IBM_CLOUD_TOKEN loaded from Google Colab secret.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from ibm_watsonx_ai import APIClient, Credentials\n",
        "from ibm_granite_community.notebook_utils import get_env_var\n",
        "import getpass\n",
        "\n",
        "credentials = Credentials(\n",
        "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
        "    api_key=get_env_var(\"IBM_CLOUD_TOKEN\")\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FHDv1d1c2hB"
      },
      "source": [
        "# Inferencing\n",
        "This cell demonstrated how we can use the model object as well as the created access token\n",
        "to pair it with parameters and input string to obtain\n",
        "the response from the the selected foundation model.\n",
        "\n",
        "## Defining the model id\n",
        "We need to specify model id that will be used for inferencing:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ykw-gyCkc2hC"
      },
      "outputs": [],
      "source": [
        "model_id = \"mistralai/mistral-medium-2505\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-0TDfhQc2hD"
      },
      "source": [
        "## Defining the model parameters\n",
        "We need to provide a set of model parameters that will influence the\n",
        "result:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JDf8ENkpc2hD"
      },
      "outputs": [],
      "source": [
        "parameters = {\n",
        "    \"frequency_penalty\": 0,\n",
        "    \"max_tokens\": 2000,\n",
        "    \"presence_penalty\": 0,\n",
        "    \"temperature\": 0,\n",
        "    \"top_p\": 1\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QB2kI_pBc2hE"
      },
      "source": [
        "## Defining the project id or space id\n",
        "The API requires project id or space id that provides the context for the call. We will obtain\n",
        "the id from the project or space in which this notebook runs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "PnukoLQEc2hE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a6523d-e6b5-4945-d3e2-37a1e1f1ab76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PROJECT_ID loaded from Google Colab secret.\n",
            "SPACE_ID loaded from Google Colab secret.\n"
          ]
        }
      ],
      "source": [
        "project_id = get_env_var(\"PROJECT_ID\")\n",
        "space_id = get_env_var(\"SPACE_ID\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJWlmXuc2hF"
      },
      "source": [
        "## Defining the Model object\n",
        "We need to define the Model object using the properties we defined so far:\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#first, run a quick API test to make sure that endpoint is working\n",
        "import os\n",
        "import requests\n",
        "\n",
        "api_key = os.getenv(\"IBM_CLOUD_TOKEN\")  # or paste your key directly\n",
        "\n",
        "response = requests.post(\n",
        "    \"https://iam.cloud.ibm.com/identity/token\",\n",
        "    data={\n",
        "        \"grant_type\": \"urn:ibm:params:oauth:grant-type:apikey\",\n",
        "        \"apikey\": api_key\n",
        "    },\n",
        "    headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
        ")\n",
        "\n",
        "print(\"Status code:\", response.status_code)\n",
        "print(\"Response body:\", response.text[:200])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QtUiJepqLKs",
        "outputId": "6cc68ed6-881c-4b0d-a4cb-5941dbfc202f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Status code: 200\n",
            "Response body: {\"access_token\":\"eyJraWQiOiIyMDE5MDcyNCIsImFsZyI6IlJTMjU2In0.eyJpYW1faWQiOiJJQk1pZC02NjUwMDBKUVdGIiwiaWQiOiJJQk1pZC02NjUwMDBKUVdGIiwicmVhbG1pZCI6IklCTWlkIiwianRpIjoiYTMyZDU4MzctNDc2OC00ZjVmLWExZGQtNjc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SR_GRumMc2hG"
      },
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models import ModelInference\n",
        "\n",
        "model = ModelInference(\n",
        "\tmodel_id = model_id,\n",
        "\tparams = parameters,\n",
        "\tcredentials = credentials,\n",
        "\tproject_id = project_id,\n",
        "\tspace_id = space_id\n",
        "\t)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzfQEoQjc2hG"
      },
      "source": [
        "## Defining the vector index\n",
        "Initialize the vector index to query when chatting with the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nvc2Rqnwc2hG"
      },
      "outputs": [],
      "source": [
        "from ibm_watsonx_ai.foundation_models.utils import Toolkit\n",
        "\n",
        "vector_index_id = \"a35ac887-d396-40e5-9d68-bfa3c9d5b45d\"\n",
        "\n",
        "def proximity_search( query ):\n",
        "\n",
        "    api_client = APIClient(\n",
        "        project_id=project_id,\n",
        "        credentials=credentials,\n",
        "    )\n",
        "\n",
        "    document_search_tool = Toolkit(\n",
        "        api_client=api_client\n",
        "    ).get_tool(\"RAGQuery\")\n",
        "\n",
        "    config = {\n",
        "    \"vectorIndexId\": vector_index_id,\n",
        "    \"projectId\": project_id\n",
        "    }\n",
        "\n",
        "    results = document_search_tool.run(\n",
        "        input=query,\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    return results.get(\"output\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vta9OfS-c2hH"
      },
      "source": [
        "## Defining the inferencing input for chat\n",
        "Foundation models supporting chat accept a system prompt that instructs the model on how to conduct the dialog. They also accept previous questions and answers to give additional context when inferencing. Each model has it's own string format for constructing the input.\n",
        "\n",
        "Let us provide the input we got from the Prompt Lab and format it for the selected model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "a-E4Ye4hc2hH"
      },
      "outputs": [],
      "source": [
        "chat_messages = [];\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzw5b69xc2hH"
      },
      "source": [
        "## Execution\n",
        "Let us now use the defined Model object, pair it with the input, and generate the response to your question:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bAY5VGNZc2hI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb412d6-a753-4fe1-afb8-fa642ebcc439"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: I need to cut down on unnecessary expenses so I can save more. Based on my monthly budget (in $), can you see anywhere where I can trim down expenses?\n",
            "{'id': 'chatcmpl-94245826ff3e48e5295cee7cb8e568ac---fa668d9a-799a-4468-90c1-0470dc871df6', 'object': 'chat.completion', 'model_id': 'mistralai/mistral-medium-2505', 'model': 'mistralai/mistral-medium-2505', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Based on your monthly budget, here are some suggestions to help you trim down expenses:\\n\\n1. **Alcohol & Bars ($50)**: Consider reducing the amount spent on alcohol and bars. This is a discretionary expense that can be easily cut down or eliminated.\\n\\n2. **Coffee Shops ($15)**: Brewing coffee at home can save you a significant amount over time. This is another discretionary expense that can be reduced.\\n\\n3. **Entertainment ($25)**: Look for free or low-cost entertainment options. This could include community events, outdoor activities, or using free resources like libraries.\\n\\n4. **Fast Food ($15)**: Reducing fast food expenses can also contribute to savings. Preparing meals at home is generally more cost-effective.\\n\\n5. **Home Improvement ($250)**: This is a significant expense. If possible, prioritize necessary improvements and postpone non-essential projects.\\n\\n6. **Music ($11)**: Consider using free music streaming services or reducing subscriptions if you have multiple ones.\\n\\n7. **Restaurants ($150)**: Similar to fast food, reducing the frequency of dining out can save money. Cooking at home is usually cheaper.\\n\\n8. **Shopping ($100)**: Evaluate your shopping habits. Look for sales, use coupons, and consider if purchases are truly necessary.\\n\\n9. **Television ($15)**: If you have multiple streaming services, consider reducing the number of subscriptions.\\n\\n### Final Answer:\\nBy cutting down on discretionary expenses like Alcohol & Bars, Coffee Shops, Entertainment, Fast Food, and Restaurants, you can save a significant amount each month. Additionally, reviewing and potentially reducing expenses in categories like Home Improvement, Music, Shopping, and Television can further increase your savings.'}, 'finish_reason': 'stop'}], 'created': 1762878542, 'model_version': '1.0.0', 'created_at': '2025-11-11T16:29:10.125Z', 'usage': {'completion_tokens': 362, 'prompt_tokens': 370, 'total_tokens': 732}, 'system': {'warnings': [{'message': 'This model is a Non-IBM Product governed by a third-party license that may impose use restrictions and other obligations. By using this model you agree to its terms as identified in the following URL.', 'id': 'disclaimer_warning', 'more_info': 'https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/fm-models.html?context=wx'}]}}\n"
          ]
        }
      ],
      "source": [
        "question = input(\"Question: \")\n",
        "grounding = proximity_search(question)\n",
        "chat_messages.append({\n",
        "    \"role\": f\"system\",\n",
        "    \"content\": f\"\"\"{grounding}\n",
        "\n",
        "You are Mixtral Chat, an AI language model developed by Mistral AI. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior. You are a AI language model designed to function as a specialized Retrieval Augmented Generation (RAG) assistant. When generating responses, prioritize correctness, i.e., ensure that your response is correct given the context and user query, and that it is grounded in the context. Furthermore, make sure that the response is supported by the given document or context. When the question cannot be answered using the context or document, output the following response: \"I cannot answer that question based on the provided document.\" Always make sure that your response is relevant to the question. If an explanation is needed, first provide the explanation or reasoning, and then give the final answer.\n",
        "\n",
        "\"\"\"\n",
        "})\n",
        "chat_messages.append({\"role\": \"user\", \"content\": question})\n",
        "generated_response = model.chat(messages=chat_messages)\n",
        "print(generated_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = generated_response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "JRzzSpBFvTzp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "def print_markdown(string):\n",
        "  display(Markdown(string))\n",
        "\n",
        "print_markdown(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "jeAb9OGPwms4",
        "outputId": "af0ad411-ed78-4aab-8fae-3592aa5eede0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on your monthly budget, here are some suggestions to help you trim down expenses:\n\n1. **Alcohol & Bars ($50)**: Consider reducing the amount spent on alcohol and bars. This is a discretionary expense that can be easily cut down or eliminated.\n\n2. **Coffee Shops ($15)**: Brewing coffee at home can save you a significant amount over time. This is another discretionary expense that can be reduced.\n\n3. **Entertainment ($25)**: Look for free or low-cost entertainment options. This could include community events, outdoor activities, or using free resources like libraries.\n\n4. **Fast Food ($15)**: Reducing fast food expenses can also contribute to savings. Preparing meals at home is generally more cost-effective.\n\n5. **Home Improvement ($250)**: This is a significant expense. If possible, prioritize necessary improvements and postpone non-essential projects.\n\n6. **Music ($11)**: Consider using free music streaming services or reducing subscriptions if you have multiple ones.\n\n7. **Restaurants ($150)**: Similar to fast food, reducing the frequency of dining out can save money. Cooking at home is usually cheaper.\n\n8. **Shopping ($100)**: Evaluate your shopping habits. Look for sales, use coupons, and consider if purchases are truly necessary.\n\n9. **Television ($15)**: If you have multiple streaming services, consider reducing the number of subscriptions.\n\n### Final Answer:\nBy cutting down on discretionary expenses like Alcohol & Bars, Coffee Shops, Entertainment, Fast Food, and Restaurants, you can save a significant amount each month. Additionally, reviewing and potentially reducing expenses in categories like Home Improvement, Music, Shopping, and Television can further increase your savings."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szTM8sotc2hI"
      },
      "source": [
        "# Next steps\n",
        "You successfully completed this notebook! You learned how to use\n",
        "watsonx.ai inferencing SDK to generate response from the foundation model\n",
        "based on the provided input, model id and model parameters. Check out the\n",
        "official watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n",
        "\n",
        "<a id=\"copyrights\"></a>\n",
        "### Copyrights\n",
        "\n",
        "Licensed Materials - Copyright Â© 2023 IBM. This notebook and its source code are released under the terms of the ILAN License.\n",
        "Use, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n",
        "\n",
        "**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n",
        "\n",
        "By downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4mSW7XA4vNYa"
      },
      "execution_count": 12,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "szTM8sotc2hI"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}